\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{1}{数学基础}}{5}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ux7b2cux4e00ux7ae0-ux6570ux5b66ux57faux7840}{{1}{5}{数学基础}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{1}{向量和矩阵}}{5}{section.1.1}}
\newlabel{ux5411ux91cfux548cux77e9ux9635}{{1}{5}{向量和矩阵}{section.1.1}{}}
\newlabel{ux6807ux91cfux5411ux91cfux77e9ux9635ux5f20ux91cfux4e4bux95f4ux7684ux8054ux7cfb}{{1.1}{5}{标量、向量、矩阵、张量之间的联系}{subsection.1.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.1}{标量、向量、矩阵、张量之间的联系}}{5}{subsection.1.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{1.1.1}{标量}}{5}{subsubsection.1.1.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{1.1.2}{向量}}{5}{subsubsection.1.1.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{1.1.3}{矩阵}}{5}{subsubsection.1.1.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{1.1.4}{张量}}{6}{subsubsection.1.1.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{1.1.5}{四者之间关系}}{6}{subsubsection.1.1.1.5}}
\newlabel{ux5f20ux91cfux4e0eux77e9ux9635ux7684ux533aux522b}{{1.2}{6}{张量与矩阵的区别}{subsection.1.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.2}{张量与矩阵的区别}}{6}{subsection.1.1.2}}
\newlabel{ux77e9ux9635ux548cux5411ux91cfux76f8ux4e58ux7ed3ux679c}{{1.3}{6}{矩阵和向量相乘结果}{subsection.1.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.3}{矩阵和向量相乘结果}}{6}{subsection.1.1.3}}
\newlabel{eq:1.3.1}{{1}{6}{矩阵和向量相乘结果}{equation.1.1.1}{}}
\newlabel{ux5411ux91cfux548cux77e9ux9635ux7684ux8303ux6570ux5f52ux7eb3}{{1.4}{6}{向量和矩阵的范数归纳}{subsection.1.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.4}{向量和矩阵的范数归纳}}{6}{subsection.1.1.4}}
\newlabel{sec:1.4.1}{{1.4.1}{7}{向量的范数}{subsubsection.1.1.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{1.4.1}{向量的范数}}{7}{subsubsection.1.1.4.1}}
\newlabel{eq:1.4.1.1}{{2}{7}{}{equation.1.1.2}{}}
\newlabel{eq:1.4.1.2}{{3}{7}{}{equation.1.1.3}{}}
\newlabel{eq:1.4.1.3}{{4}{7}{}{equation.1.1.4}{}}
\newlabel{eq:1.4.1.4}{{5}{7}{}{equation.1.1.5}{}}
\newlabel{eq:1.4.1.5}{{6}{7}{}{equation.1.1.6}{}}
\newlabel{sec:1.4.2}{{1.4.2}{8}{矩阵的范数}{subsubsection.1.1.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{1.4.2}{矩阵的范数}}{8}{subsubsection.1.1.4.2}}
\newlabel{eq:1.4.2.1}{{7}{8}{矩阵的范数}{equation.1.1.7}{}}
\newlabel{eq:1.4.2.2}{{8}{8}{}{equation.1.1.8}{}}
\newlabel{eq:1.4.2.3}{{9}{8}{}{equation.1.1.9}{}}
\newlabel{eq:1.4.2.4}{{10}{8}{}{equation.1.1.10}{}}
\newlabel{eq:1.4.2.5}{{11}{9}{}{equation.1.1.11}{}}
\newlabel{eq:1.4.2.6}{{12}{9}{}{equation.1.1.12}{}}
\newlabel{ux5982ux4f55ux5224ux65adux4e00ux4e2aux77e9ux9635ux4e3aux6b63ux5b9a}{{1.5}{9}{如何判断一个矩阵为正定}{subsection.1.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.5}{如何判断一个矩阵为正定}}{9}{subsection.1.1.5}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{2}{导数和偏导数}}{9}{section.1.2}}
\newlabel{ux5bfcux6570ux548cux504fux5bfcux6570}{{2}{9}{导数和偏导数}{section.1.2}{}}
\newlabel{ux5bfcux6570ux504fux5bfcux8ba1ux7b97}{{2.1}{9}{导数偏导计算}{subsection.1.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.1}{导数偏导计算}}{9}{subsection.1.2.1}}
\newlabel{sec:2.1.1}{{2.1.1}{10}{导数定义}{subsubsection.1.2.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{2.1.1}{导数定义}}{10}{subsubsection.1.2.1.1}}
\newlabel{ux5bfcux6570ux548cux504fux5bfcux6570ux6709ux4ec0ux4e48ux533aux522b}{{2.2}{11}{导数和偏导数有什么区别？}{subsection.1.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2}{导数和偏导数有什么区别？}}{11}{subsection.1.2.2}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{3}{特征值和特征向量}}{11}{section.1.3}}
\newlabel{ux7279ux5f81ux503cux548cux7279ux5f81ux5411ux91cf}{{3}{11}{特征值和特征向量}{section.1.3}{}}
\newlabel{ux7279ux5f81ux503cux5206ux89e3ux4e0eux7279ux5f81ux5411ux91cf}{{3.1}{11}{特征值分解与特征向量}{subsection.1.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.1}{特征值分解与特征向量}}{11}{subsection.1.3.1}}
\newlabel{ux5947ux5f02ux503cux4e0eux7279ux5f81ux503cux6709ux4ec0ux4e48ux5173ux7cfb}{{3.2}{11}{奇异值与特征值有什么关系}{subsection.1.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.2}{奇异值与特征值有什么关系}}{11}{subsection.1.3.2}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{4}{概率分布与随机变量}}{12}{section.1.4}}
\newlabel{ux6982ux7387ux5206ux5e03ux4e0eux968fux673aux53d8ux91cf}{{4}{12}{概率分布与随机变量}{section.1.4}{}}
\newlabel{ux673aux5668ux5b66ux4e60ux4e3aux4ec0ux4e48ux8981ux4f7fux7528ux6982ux7387}{{4.1}{12}{机器学习为什么要使用概率}{subsection.1.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.1}{机器学习为什么要使用概率}}{12}{subsection.1.4.1}}
\newlabel{ux53d8ux91cfux4e0eux968fux673aux53d8ux91cfux6709ux4ec0ux4e48ux533aux522b}{{4.2}{12}{变量与随机变量有什么区别}{subsection.1.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.2}{变量与随机变量有什么区别}}{12}{subsection.1.4.2}}
\newlabel{ux968fux673aux53d8ux91cfux4e0eux6982ux7387ux5206ux5e03ux7684ux8054ux7cfb}{{4.3}{13}{随机变量与概率分布的联系}{subsection.1.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.3}{随机变量与概率分布的联系}}{13}{subsection.1.4.3}}
\newlabel{ux79bbux6563ux578bux968fux673aux53d8ux91cfux548cux6982ux7387ux8d28ux91cfux51fdux6570}{{4.4}{13}{离散型随机变量和概率质量函数}{subsection.1.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.4}{离散型随机变量和概率质量函数}}{13}{subsection.1.4.4}}
\newlabel{ux8fdeux7eedux578bux968fux673aux53d8ux91cfux548cux6982ux7387ux5bc6ux5ea6ux51fdux6570}{{4.5}{13}{连续型随机变量和概率密度函数}{subsection.1.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.5}{连续型随机变量和概率密度函数}}{13}{subsection.1.4.5}}
\newlabel{ux4e3eux4f8bux7406ux89e3ux6761ux4ef6ux6982ux7387}{{4.6}{14}{举例理解条件概率}{subsection.1.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.6}{举例理解条件概率}}{14}{subsection.1.4.6}}
\newlabel{ux8054ux5408ux6982ux7387ux4e0eux8fb9ux7f18ux6982ux7387ux8054ux7cfbux533aux522b}{{4.7}{14}{联合概率与边缘概率联系区别}{subsection.1.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.7}{联合概率与边缘概率联系区别}}{14}{subsection.1.4.7}}
\newlabel{ux6761ux4ef6ux6982ux7387ux7684ux94feux5f0fux6cd5ux5219}{{4.8}{15}{条件概率的链式法则}{subsection.1.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.8}{条件概率的链式法则}}{15}{subsection.1.4.8}}
\newlabel{ux72ecux7acbux6027ux548cux6761ux4ef6ux72ecux7acbux6027}{{4.9}{15}{独立性和条件独立性}{subsection.1.4.9}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.9}{独立性和条件独立性}}{15}{subsection.1.4.9}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{5}{常见概率分布}}{16}{section.1.5}}
\newlabel{ux5e38ux89c1ux6982ux7387ux5206ux5e03}{{5}{16}{常见概率分布}{section.1.5}{}}
\newlabel{bernoulliux5206ux5e03}{{5.1}{16}{Bernoulli分布}{subsection.1.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.1}{ Bernoulli分布}}{16}{subsection.1.5.1}}
\newlabel{ux9ad8ux65afux5206ux5e03}{{5.2}{16}{高斯分布}{subsection.1.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.2}{ 高斯分布}}{16}{subsection.1.5.2}}
\newlabel{ux4f55ux65f6ux91c7ux7528ux6b63ux6001ux5206ux5e03}{{5.3}{17}{何时采用正态分布}{subsection.1.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.3}{何时采用正态分布}}{17}{subsection.1.5.3}}
\newlabel{ux6307ux6570ux5206ux5e03}{{5.4}{17}{指数分布}{subsection.1.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.4}{ 指数分布}}{17}{subsection.1.5.4}}
\newlabel{laplace-ux5206ux5e03ux62c9ux666eux62c9ux65afux5206ux5e03}{{5.5}{17}{Laplace分布（拉普拉斯分布）}{subsection.1.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.5}{ Laplace分布（拉普拉斯分布）}}{17}{subsection.1.5.5}}
\newlabel{diracux5206ux5e03ux548cux7ecfux9a8cux5206ux5e03}{{5.6}{18}{Dirac分布和经验分布}{subsection.1.5.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.6}{Dirac分布和经验分布}}{18}{subsection.1.5.6}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{6}{期望、方差、协方差、相关系数}}{18}{section.1.6}}
\newlabel{ux671fux671bux65b9ux5deeux534fux65b9ux5deeux76f8ux5173ux7cfbux6570}{{6}{18}{期望、方差、协方差、相关系数}{section.1.6}{}}
\newlabel{ux671fux671b}{{6.1}{18}{期望}{subsection.1.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.1}{ 期望}}{18}{subsection.1.6.1}}
\newlabel{ux65b9ux5dee}{{6.2}{19}{方差}{subsection.1.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.2}{方差}}{19}{subsection.1.6.2}}
\newlabel{ux534fux65b9ux5dee}{{6.3}{19}{协方差}{subsection.1.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.3}{ 协方差}}{19}{subsection.1.6.3}}
\newlabel{ux76f8ux5173ux7cfbux6570}{{6.4}{19}{相关系数}{subsection.1.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.4}{ 相关系数}}{19}{subsection.1.6.4}}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{2}{机器学习基础}}{21}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ux7b2cux4e8cux7ae0-ux673aux5668ux5b66ux4e60ux57faux7840}{{2}{21}{机器学习基础}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{1}{ 基本概念}}{21}{section.2.1}}
\newlabel{ux57faux672cux6982ux5ff5}{{1}{21}{基本概念}{section.2.1}{}}
\newlabel{ux5927ux8bddux7406ux89e3ux673aux5668ux5b66ux4e60ux672cux8d28}{{1.1}{21}{大话理解机器学习本质}{subsection.2.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.1}{大话理解机器学习本质}}{21}{subsection.2.1.1}}
\newlabel{ux4ec0ux4e48ux662fux795eux7ecfux7f51ux7edc}{{1.2}{21}{什么是神经网络}{subsection.2.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.2}{什么是神经网络}}{21}{subsection.2.1.2}}
\newlabel{ux5404ux79cdux5e38ux89c1ux7b97ux6cd5ux56feux793a}{{1.3}{22}{各种常见算法图示}{subsection.2.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.3}{各种常见算法图示}}{22}{subsection.2.1.3}}
\newlabel{ux8ba1ux7b97ux56feux7684ux5bfcux6570ux8ba1ux7b97}{{1.4}{22}{计算图的导数计算}{subsection.2.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.4}{计算图的导数计算}}{22}{subsection.2.1.4}}
\newlabel{ux7406ux89e3ux5c40ux90e8ux6700ux4f18ux4e0eux5168ux5c40ux6700ux4f18}{{1.5}{22}{理解局部最优与全局最优}{subsection.2.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.5}{理解局部最优与全局最优}}{22}{subsection.2.1.5}}
\newlabel{ux5927ux6570ux636eux4e0eux6df1ux5ea6ux5b66ux4e60ux4e4bux95f4ux7684ux5173ux7cfb}{{1.6}{23}{大数据与深度学习之间的关系}{subsection.2.1.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.6}{大数据与深度学习之间的关系}}{23}{subsection.2.1.6}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{2}{机器学习学习方式}}{23}{section.2.2}}
\newlabel{ux673aux5668ux5b66ux4e60ux5b66ux4e60ux65b9ux5f0f}{{2}{23}{机器学习学习方式}{section.2.2}{}}
\newlabel{ux76d1ux7763ux5b66ux4e60}{{2.1}{23}{监督学习}{subsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.1}{ 监督学习}}{23}{subsection.2.2.1}}
\newlabel{ux975eux76d1ux7763ux5f0fux5b66ux4e60}{{2.2}{24}{非监督式学习}{subsection.2.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2}{非监督式学习}}{24}{subsection.2.2.2}}
\newlabel{ux534aux76d1ux7763ux5f0fux5b66ux4e60}{{2.3}{24}{半监督式学习}{subsection.2.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.3}{半监督式学习}}{24}{subsection.2.2.3}}
\newlabel{ux5f31ux76d1ux7763ux5b66ux4e60}{{2.4}{24}{弱监督学习}{subsection.2.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.4}{弱监督学习}}{24}{subsection.2.2.4}}
\newlabel{ux76d1ux7763ux5b66ux4e60ux6709ux54eaux4e9bux6b65ux9aa4}{{2.5}{24}{监督学习有哪些步骤}{subsection.2.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.5}{监督学习有哪些步骤}}{24}{subsection.2.2.5}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{3}{ 分类算法}}{25}{section.2.3}}
\newlabel{ux5206ux7c7bux7b97ux6cd5}{{3}{25}{分类算法}{section.2.3}{}}
\gdef \LT@i {\LT@entry 
    {1}{27.19731pt}\LT@entry 
    {1}{27.19731pt}\LT@entry 
    {1}{27.19731pt}}
\newlabel{ux5e38ux7528ux5206ux7c7bux7b97ux6cd5ux7684ux4f18ux7f3aux70b9}{{3.1}{26}{常用分类算法的优缺点？}{subsection.2.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.1}{常用分类算法的优缺点？}}{26}{subsection.2.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 图2-3 术语的混淆矩阵}}{34}{figure.2.1}}
\newlabel{ux5206ux7c7bux7b97ux6cd5ux7684ux8bc4ux4f30ux65b9ux6cd5}{{3.2}{34}{2.8.2 分类算法的评估方法}{subsection.2.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.2}{2.8.2 分类算法的评估方法}}{34}{subsection.2.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces }}{35}{figure.2.2}}
\newlabel{ux6b63ux786eux7387ux80fdux5f88ux597dux7684ux8bc4ux4f30ux5206ux7c7bux7b97ux6cd5ux5417}{{3.3}{36}{2.8.3 正确率能很好的评估分类算法吗}{subsection.2.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.3}{2.8.3 正确率能很好的评估分类算法吗}}{36}{subsection.2.3.3}}
\newlabel{ux4ec0ux4e48ux6837ux7684ux5206ux7c7bux5668ux662fux6700ux597dux7684}{{3.4}{36}{什么样的分类器是最好的}{subsection.2.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.4}{什么样的分类器是最好的}}{36}{subsection.2.3.4}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{4}{2.9 逻辑回归}}{36}{section.2.4}}
\newlabel{ux903bux8f91ux56deux5f52}{{4}{36}{2.9 逻辑回归}{section.2.4}{}}
\newlabel{ux56deux5f52ux5212ux5206}{{4.1}{36}{2.9.1 回归划分}{subsection.2.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.1}{2.9.1 回归划分}}{36}{subsection.2.4.1}}
\newlabel{ux903bux8f91ux56deux5f52ux9002ux7528ux6027}{{4.2}{36}{逻辑回归适用性}{subsection.2.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.2}{逻辑回归适用性}}{36}{subsection.2.4.2}}
\newlabel{ux751fux6210ux6a21ux578bux548cux5224ux522bux6a21ux578bux7684ux533aux522b}{{4.3}{37}{生成模型和判别模型的区别}{subsection.2.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.3}{生成模型和判别模型的区别}}{37}{subsection.2.4.3}}
\newlabel{ux903bux8f91ux56deux5f52ux4e0eux6734ux7d20ux8d1dux53f6ux65afux6709ux4ec0ux4e48ux533aux522b}{{4.4}{37}{逻辑回归与朴素贝叶斯有什么区别}{subsection.2.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.4}{逻辑回归与朴素贝叶斯有什么区别}}{37}{subsection.2.4.4}}
\newlabel{ux7ebfux6027ux56deux5f52ux4e0eux903bux8f91ux56deux5f52ux7684ux533aux522b}{{4.5}{37}{线性回归与逻辑回归的区别}{subsection.2.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.5}{线性回归与逻辑回归的区别}}{37}{subsection.2.4.5}}
\gdef \LT@ii {\LT@entry 
    {1}{73.2362pt}\LT@entry 
    {1}{62.69684pt}\LT@entry 
    {1}{73.2362pt}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{5}{2.10 代价函数}}{38}{section.2.5}}
\newlabel{ux4ee3ux4ef7ux51fdux6570}{{5}{38}{2.10 代价函数}{section.2.5}{}}
\newlabel{ux4e3aux4ec0ux4e48ux9700ux8981ux4ee3ux4ef7ux51fdux6570}{{5.1}{38}{2.10.1 为什么需要代价函数}{subsection.2.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.1}{2.10.1 为什么需要代价函数}}{38}{subsection.2.5.1}}
\newlabel{ux4ee3ux4ef7ux51fdux6570ux4f5cux7528ux539fux7406}{{5.2}{38}{代价函数作用原理}{subsection.2.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.2}{代价函数作用原理}}{38}{subsection.2.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces }}{39}{figure.2.3}}
\newlabel{ux4e3aux4ec0ux4e48ux4ee3ux4ef7ux51fdux6570ux8981ux975eux8d1f}{{5.3}{39}{为什么代价函数要非负}{subsection.2.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.3}{为什么代价函数要非负}}{39}{subsection.2.5.3}}
\newlabel{ux5e38ux89c1ux4ee3ux4ef7ux51fdux6570}{{5.4}{39}{常见代价函数}{subsection.2.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.4}{常见代价函数}}{39}{subsection.2.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces }}{40}{figure.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces }}{41}{figure.2.5}}
\newlabel{ux4e3aux4ec0ux4e48ux7528ux4ea4ux53c9ux71b5ux4ee3ux66ffux4e8cux6b21ux4ee3ux4ef7ux51fdux6570}{{5.5}{44}{2.10.5 为什么用交叉熵代替二次代价函数}{subsection.2.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.5}{2.10.5 为什么用交叉熵代替二次代价函数}}{44}{subsection.2.5.5}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{6}{2.11 损失函数}}{44}{section.2.6}}
\newlabel{ux635fux5931ux51fdux6570}{{6}{44}{2.11 损失函数}{section.2.6}{}}
\newlabel{ux4ec0ux4e48ux662fux635fux5931ux51fdux6570}{{6.1}{44}{2.11.1 什么是损失函数}{subsection.2.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.1}{2.11.1 什么是损失函数}}{44}{subsection.2.6.1}}
\newlabel{ux5e38ux89c1ux7684ux635fux5931ux51fdux6570}{{6.2}{45}{2.11.2 常见的损失函数}{subsection.2.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.2}{2.11.2 常见的损失函数}}{45}{subsection.2.6.2}}
\newlabel{ux903bux8f91ux56deux5f52ux4e3aux4ec0ux4e48ux4f7fux7528ux5bf9ux6570ux635fux5931ux51fdux6570}{{6.3}{46}{2.11.3 逻辑回归为什么使用对数损失函数}{subsection.2.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.3}{2.11.3 逻辑回归为什么使用对数损失函数}}{46}{subsection.2.6.3}}
\newlabel{ux5bf9ux6570ux635fux5931ux51fdux6570ux662fux5982ux4f55ux5ea6ux91cfux635fux5931ux7684}{{6.4}{47}{对数损失函数是如何度量损失的}{subsection.2.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.4}{对数损失函数是如何度量损失的}}{47}{subsection.2.6.4}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{7}{ 梯度下降}}{48}{section.2.7}}
\newlabel{ux68afux5ea6ux4e0bux964d}{{7}{48}{梯度下降}{section.2.7}{}}
\newlabel{ux673aux5668ux5b66ux4e60ux4e2dux4e3aux4ec0ux4e48ux9700ux8981ux68afux5ea6ux4e0bux964d}{{7.1}{48}{机器学习中为什么需要梯度下降}{subsection.2.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.1}{机器学习中为什么需要梯度下降}}{48}{subsection.2.7.1}}
\newlabel{ux68afux5ea6ux4e0bux964dux6cd5ux7f3aux70b9}{{7.2}{48}{梯度下降法缺点}{subsection.2.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.2}{梯度下降法缺点}}{48}{subsection.2.7.2}}
\newlabel{ux68afux5ea6ux4e0bux964dux6cd5ux76f4ux89c2ux7406ux89e3}{{7.3}{48}{梯度下降法直观理解}{subsection.2.7.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.3}{梯度下降法直观理解}}{48}{subsection.2.7.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces }}{49}{figure.2.6}}
\newlabel{ux68afux5ea6ux4e0bux964dux6cd5ux7b97ux6cd5ux63cfux8ff0}{{7.4}{49}{梯度下降法算法描述}{subsection.2.7.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.4}{梯度下降法算法描述}}{49}{subsection.2.7.4}}
\newlabel{ux5982ux4f55ux5bf9ux68afux5ea6ux4e0bux964dux6cd5ux8fdbux884cux8c03ux4f18}{{7.5}{50}{如何对梯度下降法进行调优}{subsection.2.7.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.5}{如何对梯度下降法进行调优}}{50}{subsection.2.7.5}}
\newlabel{ux968fux673aux68afux5ea6ux548cux6279ux91cfux68afux5ea6ux533aux522b}{{7.6}{50}{随机梯度和批量梯度区别}{subsection.2.7.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.6}{随机梯度和批量梯度区别}}{50}{subsection.2.7.6}}
\gdef \LT@iii {\LT@entry 
    {1}{83.09999pt}\LT@entry 
    {1}{345.40309pt}}
\gdef \LT@iv {\LT@entry 
    {1}{83.77557pt}\LT@entry 
    {1}{62.69684pt}\LT@entry 
    {1}{52.15747pt}\LT@entry 
    {1}{80.20274pt}\LT@entry 
    {1}{83.77557pt}}
\newlabel{ux5404ux79cdux68afux5ea6ux4e0bux964dux6cd5ux6027ux80fdux6bd4ux8f83}{{7.7}{52}{2.12.7 各种梯度下降法性能比较}{subsection.2.7.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.7}{2.12.7 各种梯度下降法性能比较}}{52}{subsection.2.7.7}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{8}{2.14 线性判别分析（LDA）}}{52}{section.2.8}}
\newlabel{ux7ebfux6027ux5224ux522bux5206ux6790lda}{{8}{52}{2.14 线性判别分析（LDA）}{section.2.8}{}}
\newlabel{ldaux601dux60f3ux603bux7ed3}{{8.1}{52}{2.14.1 LDA思想总结}{subsection.2.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.1}{2.14.1 LDA思想总结}}{52}{subsection.2.8.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces }}{53}{figure.2.7}}
\newlabel{ux56feux89e3ldaux6838ux5fc3ux601dux60f3}{{8.2}{53}{2.14.2 图解LDA核心思想}{subsection.2.8.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.2}{2.14.2 图解LDA核心思想}}{53}{subsection.2.8.2}}
\newlabel{ux4e8cux7c7bldaux7b97ux6cd5ux539fux7406}{{8.3}{53}{2.14.3 二类LDA算法原理}{subsection.2.8.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.3}{2.14.3 二类LDA算法原理}}{53}{subsection.2.8.3}}
\gdef \LT@v {\LT@entry 
    {1}{41.6181pt}\LT@entry 
    {1}{536.70491pt}\LT@entry 
    {1}{181.88657pt}}
\newlabel{ldaux7b97ux6cd5ux6d41ux7a0bux603bux7ed3}{{8.4}{54}{LDA算法流程总结}{subsection.2.8.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.4}{LDA算法流程总结}}{54}{subsection.2.8.4}}
\newlabel{ldaux548cpcaux533aux522b}{{8.5}{54}{LDA和PCA区别}{subsection.2.8.5}{}}
\gdef \LT@vi {\LT@entry 
    {1}{31.50154pt}\LT@entry 
    {1}{27.19731pt}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.5}{LDA和PCA区别}}{55}{table.2.5}}
\newlabel{ldaux4f18ux7f3aux70b9}{{8.6}{55}{LDA优缺点}{subsection.2.8.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.6}{ LDA优缺点}}{58}{table.2.6}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{9}{主成分分析（PCA）}}{58}{section.2.9}}
\newlabel{ux4e3bux6210ux5206ux5206ux6790pca}{{9}{58}{主成分分析（PCA）}{section.2.9}{}}
\newlabel{ux4e3bux6210ux5206ux5206ux6790pcaux601dux60f3ux603bux7ed3}{{9.1}{58}{主成分分析（PCA）思想总结}{subsection.2.9.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.1}{主成分分析（PCA）思想总结}}{58}{subsection.2.9.1}}
\newlabel{ux56feux89e3pcaux6838ux5fc3ux601dux60f3}{{9.2}{58}{图解PCA核心思想}{subsection.2.9.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.2}{图解PCA核心思想}}{58}{subsection.2.9.2}}
\newlabel{pcaux7b97ux6cd5ux63a8ux7406}{{9.3}{58}{PCA算法推理}{subsection.2.9.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.3}{ PCA算法推理}}{58}{subsection.2.9.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces }}{59}{figure.2.8}}
\gdef \LT@vii {\LT@entry 
    {1}{31.50154pt}\LT@entry 
    {1}{27.19731pt}}
\newlabel{pcaux7b97ux6cd5ux6d41ux7a0bux603bux7ed3}{{9.4}{60}{PCA算法流程总结}{subsection.2.9.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.4}{PCA算法流程总结}}{60}{subsection.2.9.4}}
\newlabel{pcaux7b97ux6cd5ux4e3bux8981ux4f18ux7f3aux70b9}{{9.5}{60}{PCA算法主要优缺点}{subsection.2.9.5}{}}
\gdef \LT@viii {\LT@entry 
    {1}{91.20584pt}\LT@entry 
    {1}{178.62988pt}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.5}{PCA算法主要优缺点}}{63}{table.2.7}}
\newlabel{ux964dux7ef4ux7684ux5fc5ux8981ux6027ux53caux76eeux7684}{{9.6}{63}{降维的必要性及目的}{subsection.2.9.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.6}{降维的必要性及目的}}{63}{subsection.2.9.6}}
\newlabel{kpcaux4e0epcaux7684ux533aux522b}{{9.7}{63}{KPCA与PCA的区别}{subsection.2.9.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.7}{KPCA与PCA的区别}}{63}{subsection.2.9.7}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{10}{ 模型评估}}{63}{section.2.10}}
\newlabel{ux6a21ux578bux8bc4ux4f30}{{10}{63}{模型评估}{section.2.10}{}}
\newlabel{ux6a21ux578bux8bc4ux4f30ux5e38ux7528ux65b9ux6cd5}{{10.1}{63}{模型评估常用方法？}{subsection.2.10.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.1}{模型评估常用方法？}}{63}{subsection.2.10.1}}
\gdef \LT@ix {\LT@entry 
    {1}{170.0087pt}\LT@entry 
    {1}{52.88469pt}}
\newlabel{ux8befux5deeux504fux5deeux548cux65b9ux5deeux6709ux4ec0ux4e48ux533aux522bux548cux8054ux7cfb}{{10.2}{64}{2.16.2 误差、偏差和方差有什么区别和联系}{subsection.2.10.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.2}{2.16.2 误差、偏差和方差有什么区别和联系}}{64}{subsection.2.10.2}}
\newlabel{ux7ecfux9a8cux8befux5deeux4e0eux6cdbux5316ux8befux5dee}{{10.3}{65}{经验误差与泛化误差}{subsection.2.10.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.3}{经验误差与泛化误差}}{65}{subsection.2.10.3}}
\newlabel{ux56feux89e3ux6b20ux62dfux5408ux8fc7ux62dfux5408}{{10.4}{65}{图解欠拟合、过拟合}{subsection.2.10.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.4}{图解欠拟合、过拟合}}{65}{subsection.2.10.4}}
\gdef \LT@x {\LT@entry 
    {1}{227.36394pt}\LT@entry 
    {1}{124.32054pt}\LT@entry 
    {1}{135.58713pt}}
\newlabel{ux5982ux4f55ux89e3ux51b3ux8fc7ux62dfux5408ux4e0eux6b20ux62dfux5408}{{10.5}{66}{如何解决过拟合与欠拟合}{subsection.2.10.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.5}{如何解决过拟合与欠拟合}}{66}{subsection.2.10.5}}
\newlabel{ux4ea4ux53c9ux9a8cux8bc1ux7684ux4e3bux8981ux4f5cux7528}{{10.6}{66}{交叉验证的主要作用}{subsection.2.10.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.6}{交叉验证的主要作用}}{66}{subsection.2.10.6}}
\newlabel{ux7406ux89e3kux6298ux4ea4ux53c9ux9a8cux8bc1}{{10.7}{66}{理解k折交叉验证}{subsection.2.10.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.7}{理解k折交叉验证}}{66}{subsection.2.10.7}}
\newlabel{ux6df7ux6dc6ux77e9ux9635}{{10.8}{66}{混淆矩阵}{subsection.2.10.8}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.8}{混淆矩阵}}{66}{subsection.2.10.8}}
\gdef \LT@xi {\LT@entry 
    {1}{89.92003pt}\LT@entry 
    {1}{149.63612pt}\LT@entry 
    {1}{149.63612pt}}
\newlabel{ux9519ux8befux7387ux53caux7cbeux5ea6}{{10.9}{67}{错误率及精度}{subsection.2.10.9}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.9}{错误率及精度}}{67}{subsection.2.10.9}}
\newlabel{ux67e5ux51c6ux7387ux4e0eux67e5ux5168ux7387}{{10.10}{67}{查准率与查全率}{subsection.2.10.10}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.10}{查准率与查全率}}{67}{subsection.2.10.10}}
\newlabel{rocux4e0eauc}{{10.11}{67}{ROC与AUC}{subsection.2.10.11}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.11}{ROC与AUC}}{67}{subsection.2.10.11}}
\gdef \LT@xii {\LT@entry 
    {1}{31.07875pt}\LT@entry 
    {1}{132.59395pt}\LT@entry 
    {1}{52.15749pt}}
\newlabel{ux5982ux4f55ux753brocux66f2ux7ebf}{{10.12}{68}{如何画ROC曲线}{subsection.2.10.12}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.12}{如何画ROC曲线}}{68}{subsection.2.10.12}}
\newlabel{ux5982ux4f55ux8ba1ux7b97tprfpr}{{10.13}{68}{如何计算TPR，FPR}{subsection.2.10.13}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.13}{如何计算TPR，FPR}}{68}{subsection.2.10.13}}
\gdef \LT@xiii {\LT@entry 
    {1}{31.07875pt}\LT@entry 
    {1}{38.25606pt}\LT@entry 
    {1}{38.98328pt}}
\gdef \LT@xiv {\LT@entry 
    {1}{31.07875pt}\LT@entry 
    {1}{38.25606pt}\LT@entry 
    {1}{38.98328pt}}
\gdef \LT@xv {\LT@entry 
    {1}{31.07875pt}\LT@entry 
    {1}{38.25606pt}\LT@entry 
    {1}{38.98328pt}}
\gdef \LT@xvi {\LT@entry 
    {1}{31.07875pt}\LT@entry 
    {1}{38.25606pt}\LT@entry 
    {1}{38.98328pt}}
\newlabel{ux5982ux4f55ux8ba1ux7b97auc}{{10.14}{69}{如何计算AUC}{subsection.2.10.14}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.14}{如何计算AUC}}{69}{subsection.2.10.14}}
\newlabel{ux4e3aux4ec0ux4e48ux4f7fux7528rocux548caucux8bc4ux4ef7ux5206ux7c7bux5668}{{10.15}{70}{为什么使用Roc和Auc评价分类器}{subsection.2.10.15}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.15}{为什么使用Roc和Auc评价分类器}}{70}{subsection.2.10.15}}
\newlabel{ux76f4ux89c2ux7406ux89e3auc}{{10.16}{70}{直观理解AUC}{subsection.2.10.16}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.16}{直观理解AUC}}{70}{subsection.2.10.16}}
\newlabel{ux4ee3ux4ef7ux654fux611fux9519ux8befux7387ux4e0eux4ee3ux4ef7ux66f2ux7ebf}{{10.17}{70}{代价敏感错误率与代价曲线}{subsection.2.10.17}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.17}{代价敏感错误率与代价曲线}}{70}{subsection.2.10.17}}
\newlabel{ux6a21ux578bux6709ux54eaux4e9bux6bd4ux8f83ux68c0ux9a8cux65b9ux6cd5}{{10.18}{71}{模型有哪些比较检验方法}{subsection.2.10.18}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.18}{模型有哪些比较检验方法}}{71}{subsection.2.10.18}}
\newlabel{ux4e3aux4ec0ux4e48ux4f7fux7528ux6807ux51c6ux5dee}{{10.19}{71}{为什么使用标准差}{subsection.2.10.19}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.19}{为什么使用标准差}}{71}{subsection.2.10.19}}
\newlabel{ux7c7bux522bux4e0dux5e73ux8861ux4ea7ux751fux539fux56e0}{{10.20}{72}{类别不平衡产生原因}{subsection.2.10.20}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.20}{类别不平衡产生原因}}{72}{subsection.2.10.20}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{11}{决策树}}{73}{section.2.11}}
\newlabel{ux51b3ux7b56ux6811}{{11}{73}{决策树}{section.2.11}{}}
\newlabel{ux51b3ux7b56ux6811ux7684ux57faux672cux539fux7406}{{11.1}{73}{决策树的基本原理}{subsection.2.11.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{11.1}{决策树的基本原理}}{73}{subsection.2.11.1}}
\newlabel{ux51b3ux7b56ux6811ux7684ux4e09ux8981ux7d20}{{11.2}{73}{决策树的三要素？}{subsection.2.11.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{11.2}{决策树的三要素？}}{73}{subsection.2.11.2}}
\newlabel{ux51b3ux7b56ux6811ux5b66ux4e60ux57faux672cux7b97ux6cd5}{{11.3}{73}{决策树学习基本算法}{subsection.2.11.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{11.3}{决策树学习基本算法}}{73}{subsection.2.11.3}}
\newlabel{ux51b3ux7b56ux6811ux7b97ux6cd5ux4f18ux7f3aux70b9}{{11.4}{73}{决策树算法优缺点}{subsection.2.11.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{11.4}{决策树算法优缺点}}{73}{subsection.2.11.4}}
\newlabel{ux71b5ux7684ux6982ux5ff5ux4ee5ux53caux7406ux89e3}{{11.5}{74}{熵的概念以及理解}{subsection.2.11.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{11.5}{熵的概念以及理解}}{74}{subsection.2.11.5}}
\newlabel{ux4fe1ux606fux589eux76caux7684ux7406ux89e3}{{11.6}{74}{信息增益的理解}{subsection.2.11.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{11.6}{信息增益的理解}}{74}{subsection.2.11.6}}
\newlabel{ux526aux679dux5904ux7406ux7684ux4f5cux7528ux53caux7b56ux7565}{{11.7}{74}{剪枝处理的作用及策略}{subsection.2.11.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{11.7}{剪枝处理的作用及策略}}{74}{subsection.2.11.7}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{12}{ 支持向量机}}{75}{section.2.12}}
\newlabel{ux652fux6301ux5411ux91cfux673a}{{12}{75}{支持向量机}{section.2.12}{}}
\newlabel{ux4ec0ux4e48ux662fux652fux6301ux5411ux91cfux673a}{{12.1}{75}{什么是支持向量机}{subsection.2.12.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{12.1}{什么是支持向量机}}{75}{subsection.2.12.1}}
\newlabel{ux652fux6301ux5411ux91cfux673aux80fdux89e3ux51b3ux54eaux4e9bux95eeux9898}{{12.2}{75}{支持向量机能解决哪些问题}{subsection.2.12.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{12.2}{支持向量机能解决哪些问题}}{75}{subsection.2.12.2}}
\newlabel{ux6838ux51fdux6570ux7279ux70b9ux53caux5176ux4f5cux7528}{{12.3}{75}{核函数特点及其作用}{subsection.2.12.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{12.3}{核函数特点及其作用}}{76}{subsection.2.12.3}}
\newlabel{svmux4e3aux4ec0ux4e48ux5f15ux5165ux5bf9ux5076ux95eeux9898}{{12.4}{76}{SVM为什么引入对偶问题}{subsection.2.12.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{12.4}{SVM为什么引入对偶问题}}{76}{subsection.2.12.4}}
\newlabel{ux5982ux4f55ux7406ux89e3svmux4e2dux7684ux5bf9ux5076ux95eeux9898}{{12.5}{76}{如何理解SVM中的对偶问题}{subsection.2.12.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{12.5}{如何理解SVM中的对偶问题}}{76}{subsection.2.12.5}}
\newlabel{ux5e38ux89c1ux7684ux6838ux51fdux6570ux6709ux54eaux4e9b}{{12.6}{77}{常见的核函数有哪些}{subsection.2.12.6}{}}
\gdef \LT@xvii {\LT@entry 
    {1}{100.30386pt}\LT@entry 
    {1}{199.2031pt}\LT@entry 
    {1}{121.79884pt}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{12.6}{常见的核函数有哪些}}{78}{table.2.17}}
\newlabel{svmux4e3bux8981ux7279ux70b9}{{12.7}{78}{SVM主要特点}{subsection.2.12.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{12.7}{ SVM主要特点}}{78}{subsection.2.12.7}}
\newlabel{svmux4e3bux8981ux7f3aux70b9}{{12.8}{79}{SVM主要缺点}{subsection.2.12.8}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{12.8}{ SVM主要缺点}}{79}{subsection.2.12.8}}
\newlabel{ux903bux8f91ux56deux5f52ux4e0esvmux7684ux5f02ux540c}{{12.9}{79}{逻辑回归与SVM的异同}{subsection.2.12.9}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{12.9}{逻辑回归与SVM的异同}}{79}{subsection.2.12.9}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{13}{贝叶斯分类器}}{81}{section.2.13}}
\newlabel{ux8d1dux53f6ux65afux5206ux7c7bux5668}{{13}{81}{贝叶斯分类器}{section.2.13}{}}
\newlabel{ux56feux89e3ux6781ux5927ux4f3cux7136ux4f30ux8ba1}{{13.1}{81}{图解极大似然估计}{subsection.2.13.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{13.1}{图解极大似然估计}}{81}{subsection.2.13.1}}
\newlabel{ux6781ux5927ux4f3cux7136ux4f30ux8ba1ux539fux7406}{{13.2}{81}{极大似然估计原理}{subsection.2.13.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{13.2}{极大似然估计原理}}{81}{subsection.2.13.2}}
\newlabel{ux8d1dux53f6ux65afux5206ux7c7bux5668ux57faux672cux539fux7406}{{13.3}{81}{贝叶斯分类器基本原理}{subsection.2.13.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{13.3}{贝叶斯分类器基本原理}}{81}{subsection.2.13.3}}
\gdef \LT@xviii {\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{34.00868pt}\LT@entry 
    {1}{41.6181pt}\LT@entry 
    {1}{31.07874pt}}
\newlabel{ux6734ux7d20ux8d1dux53f6ux65afux5206ux7c7bux5668}{{13.4}{82}{朴素贝叶斯分类器}{subsection.2.13.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{13.4}{朴素贝叶斯分类器}}{82}{subsection.2.13.4}}
\newlabel{ux4e3eux4f8bux7406ux89e3ux6734ux7d20ux8d1dux53f6ux65afux5206ux7c7bux5668}{{13.5}{82}{举例理解朴素贝叶斯分类器}{subsection.2.13.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{13.5}{举例理解朴素贝叶斯分类器}}{82}{subsection.2.13.5}}
\gdef \LT@xix {\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{31.07874pt}\LT@entry 
    {1}{34.00868pt}\LT@entry 
    {1}{41.6181pt}\LT@entry 
    {1}{31.07874pt}}
\newlabel{ux534aux6734ux7d20ux8d1dux53f6ux65afux5206ux7c7bux5668}{{13.6}{85}{半朴素贝叶斯分类器}{subsection.2.13.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{13.6}{半朴素贝叶斯分类器}}{85}{subsection.2.13.6}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{14}{ EM算法}}{85}{section.2.14}}
\newlabel{emux7b97ux6cd5}{{14}{85}{EM算法}{section.2.14}{}}
\newlabel{emux7b97ux6cd5ux57faux672cux601dux60f3}{{14.1}{85}{EM算法基本思想}{subsection.2.14.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{14.1}{EM算法基本思想}}{85}{subsection.2.14.1}}
\newlabel{emux7b97ux6cd5ux63a8ux5bfc}{{14.2}{85}{EM算法推导}{subsection.2.14.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{14.2}{EM算法推导}}{85}{subsection.2.14.2}}
\newlabel{ux56feux89e3emux7b97ux6cd5}{{14.3}{86}{图解EM算法}{subsection.2.14.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{14.3}{ 图解EM算法}}{86}{subsection.2.14.3}}
\newlabel{emux7b97ux6cd5ux6d41ux7a0b}{{14.4}{87}{EM算法流程}{subsection.2.14.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{14.4}{ EM算法流程}}{87}{subsection.2.14.4}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{15}{ 降维和聚类}}{87}{section.2.15}}
\newlabel{ux964dux7ef4ux548cux805aux7c7b}{{15}{87}{降维和聚类}{section.2.15}{}}
\newlabel{ux56feux89e3ux4e3aux4ec0ux4e48ux4f1aux4ea7ux751fux7ef4ux6570ux707eux96be}{{15.1}{87}{图解为什么会产生维数灾难}{subsection.2.15.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.1}{图解为什么会产生维数灾难}}{87}{subsection.2.15.1}}
\newlabel{ux600eux6837ux907fux514dux7ef4ux6570ux707eux96be}{{15.2}{88}{怎样避免维数灾难}{subsection.2.15.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.2}{怎样避免维数灾难}}{89}{subsection.2.15.2}}
\newlabel{ux805aux7c7bux548cux964dux7ef4ux6709ux4ec0ux4e48ux533aux522bux4e0eux8054ux7cfb}{{15.3}{89}{聚类和降维有什么区别与联系}{subsection.2.15.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.3}{聚类和降维有什么区别与联系}}{89}{subsection.2.15.3}}
\newlabel{ux6709ux54eaux4e9bux805aux7c7bux7b97ux6cd5ux4f18ux52a3ux8861ux91cfux6807ux51c6}{{15.4}{89}{有哪些聚类算法优劣衡量标准}{subsection.2.15.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.4}{有哪些聚类算法优劣衡量标准}}{89}{subsection.2.15.4}}
\newlabel{ux805aux7c7bux548cux5206ux7c7bux6709ux4ec0ux4e48ux533aux522b}{{15.5}{89}{聚类和分类有什么区别}{subsection.2.15.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.5}{聚类和分类有什么区别}}{89}{subsection.2.15.5}}
\gdef \LT@xx {\LT@entry 
    {1}{96.08556pt}\LT@entry 
    {1}{52.15747pt}\LT@entry 
    {1}{83.77557pt}\LT@entry 
    {1}{41.6181pt}\LT@entry 
    {1}{94.31494pt}\LT@entry 
    {1}{52.15747pt}\LT@entry 
    {1}{52.15747pt}}
\newlabel{ux4e0dux540cux805aux7c7bux7b97ux6cd5ux7279ux70b9ux6027ux80fdux6bd4ux8f83}{{15.6}{90}{不同聚类算法特点性能比较}{subsection.2.15.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.6}{不同聚类算法特点性能比较}}{90}{table.2.20}}
\newlabel{ux56dbux79cdux5e38ux7528ux805aux7c7bux65b9ux6cd5ux4e4bux6bd4ux8f83}{{15.7}{90}{四种常用聚类方法之比较}{subsection.2.15.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.7}{四种常用聚类方法之比较}}{90}{subsection.2.15.7}}
\newlabel{k-meansux805aux7c7bux7b97ux6cd5}{{15.8}{90}{k-means聚类算法}{subsection.2.15.8}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.8}{k-means聚类算法}}{90}{subsection.2.15.8}}
\newlabel{ux5c42ux6b21ux805aux7c7bux7b97ux6cd5}{{15.9}{91}{层次聚类算法}{subsection.2.15.9}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.9}{层次聚类算法}}{91}{subsection.2.15.9}}
\newlabel{somux805aux7c7bux7b97ux6cd5}{{15.10}{91}{SOM聚类算法}{subsection.2.15.10}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.10}{SOM聚类算法}}{91}{subsection.2.15.10}}
\newlabel{fcmux805aux7c7bux7b97ux6cd5}{{15.11}{91}{FCM聚类算法}{subsection.2.15.11}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.11}{ FCM聚类算法}}{91}{subsection.2.15.11}}
\gdef \LT@xxi {\LT@entry 
    {1}{52.15749pt}\LT@entry 
    {1}{62.69685pt}\LT@entry 
    {1}{61.57968pt}\LT@entry 
    {1}{91.14261pt}}
\newlabel{ux56dbux79cdux805aux7c7bux7b97ux6cd5ux8bd5ux9a8c}{{15.12}{92}{四种聚类算法试验}{subsection.2.15.12}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{15.12}{四种聚类算法试验}}{92}{subsection.2.15.12}}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{3}{深度学习基础}}{95}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ux7b2cux4e09ux7ae0-ux6df1ux5ea6ux5b66ux4e60ux57faux7840}{{3}{95}{深度学习基础}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{1}{基本概念}}{95}{section.3.1}}
\newlabel{ux57faux672cux6982ux5ff5}{{1}{95}{基本概念}{section.3.1}{}}
\newlabel{ux795eux7ecfux7f51ux7edcux7ec4ux6210}{{1.1}{95}{神经网络组成？}{subsection.3.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.1}{神经网络组成？}}{95}{subsection.3.1.1}}
\newlabel{ux795eux7ecfux7f51ux7edcux6709ux54eaux4e9bux5e38ux7528ux6a21ux578bux7ed3ux6784}{{1.2}{96}{神经网络有哪些常用模型结构？}{subsection.3.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.2}{神经网络有哪些常用模型结构？}}{96}{subsection.3.1.2}}
\newlabel{ux5982ux4f55ux9009ux62e9ux6df1ux5ea6ux5b66ux4e60ux5f00ux53d1ux5e73ux53f0}{{1.3}{96}{如何选择深度学习开发平台？}{subsection.3.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.3}{如何选择深度学习开发平台？}}{96}{subsection.3.1.3}}
\newlabel{ux4e3aux4ec0ux4e48ux4f7fux7528ux6df1ux5c42ux8868ux793a}{{1.4}{96}{为什么使用深层表示?}{subsection.3.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.4}{为什么使用深层表示?}}{96}{subsection.3.1.4}}
\newlabel{ux4e3aux4ec0ux4e48ux6df1ux5c42ux795eux7ecfux7f51ux7edcux96beux4ee5ux8badux7ec3}{{1.5}{97}{为什么深层神经网络难以训练？}{subsection.3.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.5}{为什么深层神经网络难以训练？}}{97}{subsection.3.1.5}}
\newlabel{ux6df1ux5ea6ux5b66ux4e60ux548cux673aux5668ux5b66ux4e60ux6709ux4ec0ux4e48ux4e0dux540c}{{1.6}{97}{深度学习和机器学习有什么不同？}{subsection.3.1.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.6}{深度学习和机器学习有什么不同？}}{97}{subsection.3.1.6}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{2}{网络操作与计算}}{97}{section.3.2}}
\newlabel{ux7f51ux7edcux64cdux4f5cux4e0eux8ba1ux7b97}{{2}{97}{网络操作与计算}{section.3.2}{}}
\newlabel{ux524dux5411ux4f20ux64adux4e0eux53cdux5411ux4f20ux64ad}{{2.1}{97}{前向传播与反向传播？}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.1}{前向传播与反向传播？}}{97}{subsection.3.2.1}}
\newlabel{ux5982ux4f55ux8ba1ux7b97ux795eux7ecfux7f51ux7edcux7684ux8f93ux51fa}{{2.2}{98}{如何计算神经网络的输出？}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2}{如何计算神经网络的输出？}}{98}{subsection.3.2.2}}
\newlabel{ux5982ux4f55ux8ba1ux7b97ux5377ux79efux795eux7ecfux7f51ux7edcux8f93ux51faux503c}{{2.3}{99}{如何计算卷积神经网络输出值？}{subsection.3.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.3}{如何计算卷积神经网络输出值？}}{99}{subsection.3.2.3}}
\newlabel{ux5982ux4f55ux8ba1ux7b97-pooling-ux5c42ux8f93ux51faux503cux8f93ux51faux503c}{{2.4}{99}{如何计算 Pooling层输出值输出值？}{subsection.3.2.4}{}}
\newlabel{ux5b9eux4f8bux7406ux89e3ux53cdux5411ux4f20ux64ad}{{2.5}{99}{实例理解反向传播}{subsection.3.2.5}{}}
\newlabel{ux795eux7ecfux7f51ux7edcux66f4ux6df1ux6709ux4ec0ux4e48ux610fux4e49}{{2.6}{99}{神经网络更深有什么意义？}{subsection.3.2.6}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{3}{ 超参数}}{99}{section.3.3}}
\newlabel{ux8d85ux53c2ux6570}{{2.3}{99}{如何计算卷积神经网络输出值？}{section.3.3}{}}
\newlabel{ux4ec0ux4e48ux662fux8d85ux53c2ux6570}{{3.1}{99}{什么是超参数？}{subsection.3.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.1}{什么是超参数？}}{99}{subsection.3.3.1}}
\newlabel{ux5982ux4f55ux5bfbux627eux8d85ux53c2ux6570ux7684ux6700ux4f18ux503c}{{3.2}{99}{如何寻找超参数的最优值？}{subsection.3.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.2}{如何寻找超参数的最优值？}}{99}{subsection.3.3.2}}
\newlabel{ux8d85ux53c2ux6570ux641cux7d22ux4e00ux822cux8fc7ux7a0b}{{3.3}{100}{超参数搜索一般过程？}{subsection.3.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.3}{超参数搜索一般过程？}}{100}{subsection.3.3.3}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{4}{ 激活函数}}{100}{section.3.4}}
\newlabel{ux6fc0ux6d3bux51fdux6570}{{4}{100}{激活函数}{section.3.4}{}}
\newlabel{ux4e3aux4ec0ux4e48ux9700ux8981ux975eux7ebfux6027ux6fc0ux6d3bux51fdux6570}{{4.1}{100}{为什么需要非线性激活函数？}{subsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.1}{为什么需要非线性激活函数？}}{100}{subsection.3.4.1}}
\newlabel{ux5e38ux89c1ux7684ux6fc0ux6d3bux51fdux6570ux53caux56feux50cf}{{4.2}{100}{常见的激活函数及图像}{subsection.3.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.2}{常见的激活函数及图像}}{100}{subsection.3.4.2}}
\gdef \LT@xxii {\LT@entry 
    {1}{44.40117pt}\LT@entry 
    {1}{104.60155pt}\LT@entry 
    {1}{139.0027pt}\LT@entry 
    {1}{139.0027pt}}
\newlabel{ux5e38ux89c1ux6fc0ux6d3bux51fdux6570ux7684ux5bfcux6570ux8ba1ux7b97}{{4.3}{101}{3.4.3 常见激活函数的导数计算？}{subsection.3.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.3}{3.4.3 常见激活函数的导数计算？}}{101}{subsection.3.4.3}}
\newlabel{ux6fc0ux6d3bux51fdux6570ux6709ux54eaux4e9bux6027ux8d28}{{4.4}{101}{激活函数有哪些性质？}{subsection.3.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.4}{激活函数有哪些性质？}}{101}{subsection.3.4.4}}
\newlabel{ux5982ux4f55ux9009ux62e9ux6fc0ux6d3bux51fdux6570}{{4.5}{102}{如何选择激活函数？}{subsection.3.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.5}{如何选择激活函数？}}{102}{subsection.3.4.5}}
\newlabel{ux4f7fux7528-relu-ux6fc0ux6d3bux51fdux6570ux7684ux4f18ux70b9}{{4.6}{102}{使用 ReLu激活函数的优点？}{subsection.3.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.6}{ 使用 ReLu激活函数的优点？}}{102}{subsection.3.4.6}}
\newlabel{ux4ec0ux4e48ux65f6ux5019ux53efux4ee5ux7528ux7ebfux6027ux6fc0ux6d3bux51fdux6570}{{4.7}{102}{3.4.7 什么时候可以用线性激活函数？}{subsection.3.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.7}{3.4.7 什么时候可以用线性激活函数？}}{102}{subsection.3.4.7}}
\newlabel{ux600eux6837ux7406ux89e3-relu-0-ux65f6ux662fux975eux7ebfux6027ux6fc0ux6d3bux51fdux6570}{{4.8}{102}{3.4.8 怎样理解 Relu（\textless {} 0 时）是非线性激活函数？}{subsection.3.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.8}{3.4.8 怎样理解 Relu（\textless {} 0 时）是非线性激活函数？}}{102}{subsection.3.4.8}}
\newlabel{softmax-ux5b9aux4e49ux53caux4f5cux7528}{{4.9}{103}{3.4.9 Softmax 定义及作用}{subsection.3.4.9}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.9}{3.4.9 Softmax 定义及作用}}{103}{subsection.3.4.9}}
\newlabel{softmax-ux51fdux6570ux5982ux4f55ux5e94ux7528ux4e8eux591aux5206ux7c7b}{{4.10}{103}{3.4.10 Softmax 函数如何应用于多分类？}{subsection.3.4.10}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.10}{3.4.10 Softmax 函数如何应用于多分类？}}{103}{subsection.3.4.10}}
\newlabel{ux4ea4ux53c9ux71b5ux4ee3ux4ef7ux51fdux6570ux5b9aux4e49ux53caux5176ux6c42ux5bfcux63a8ux5bfc}{{4.11}{104}{3.4.11 交叉熵代价函数定义及其求导推导}{subsection.3.4.11}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.11}{3.4.11 交叉熵代价函数定义及其求导推导}}{104}{subsection.3.4.11}}
\newlabel{ux4e3aux4ec0ux4e48tanhux6536ux655bux901fux5ea6ux6bd4sigmoidux5feb}{{4.12}{105}{3.4.12 为什么Tanh收敛速度比Sigmoid快？}{subsection.3.4.12}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.12}{3.4.12 为什么Tanh收敛速度比Sigmoid快？}}{105}{subsection.3.4.12}}
\newlabel{ux5185ux805aux5916ux65a5---center-loss}{{4.13}{105}{3.4.12 内聚外斥 - Center Loss}{subsection.3.4.13}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.13}{3.4.12 内聚外斥 - Center Loss}}{105}{subsection.3.4.13}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{5}{3.5 Batch\_Size}}{106}{section.3.5}}
\newlabel{batch_size}{{5}{106}{3.5 Batch\_Size}{section.3.5}{}}
\newlabel{ux4e3aux4ec0ux4e48ux9700ux8981-batch_size}{{5.1}{106}{3.5.1 为什么需要 Batch\_Size？}{subsection.3.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.1}{3.5.1 为什么需要 Batch\_Size？}}{106}{subsection.3.5.1}}
\newlabel{batch_size-ux503cux7684ux9009ux62e9}{{5.2}{106}{3.5.2 Batch\_Size 值的选择}{subsection.3.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.2}{3.5.2 Batch\_Size 值的选择}}{106}{subsection.3.5.2}}
\newlabel{ux5728ux5408ux7406ux8303ux56f4ux5185ux589eux5927batch_sizeux6709ux4f55ux597dux5904}{{5.3}{107}{3.5.3 在合理范围内，增大Batch\_Size有何好处？}{subsection.3.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.3}{3.5.3 在合理范围内，增大Batch\_Size有何好处？}}{107}{subsection.3.5.3}}
\newlabel{ux76f2ux76eeux589eux5927-batch_size-ux6709ux4f55ux574fux5904}{{5.4}{107}{3.5.4 盲目增大 Batch\_Size 有何坏处？}{subsection.3.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.4}{3.5.4 盲目增大 Batch\_Size 有何坏处？}}{107}{subsection.3.5.4}}
\newlabel{ux8c03ux8282-batch_size-ux5bf9ux8badux7ec3ux6548ux679cux5f71ux54cdux5230ux5e95ux5982ux4f55}{{5.5}{107}{3.5.5 调节 Batch\_Size 对训练效果影响到底如何？}{subsection.3.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.5}{3.5.5 调节 Batch\_Size 对训练效果影响到底如何？}}{107}{subsection.3.5.5}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{6}{3.6 归一化}}{107}{section.3.6}}
\newlabel{ux5f52ux4e00ux5316}{{6}{107}{3.6 归一化}{section.3.6}{}}
\newlabel{ux5f52ux4e00ux5316ux542bux4e49}{{6.1}{107}{3.6.1 归一化含义？}{subsection.3.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.1}{3.6.1 归一化含义？}}{107}{subsection.3.6.1}}
\newlabel{ux4e3aux4ec0ux4e48ux8981ux5f52ux4e00ux5316}{{6.2}{108}{3.6.2 为什么要归一化？}{subsection.3.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.2}{3.6.2 为什么要归一化？}}{108}{subsection.3.6.2}}
\newlabel{ux4e3aux4ec0ux4e48ux5f52ux4e00ux5316ux80fdux63d0ux9ad8ux6c42ux89e3ux6700ux4f18ux89e3ux901fux5ea6}{{6.3}{108}{3.6.3 为什么归一化能提高求解最优解速度？}{subsection.3.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.3}{3.6.3 为什么归一化能提高求解最优解速度？}}{108}{subsection.3.6.3}}
\newlabel{d-ux56feux89e3ux672aux5f52ux4e00ux5316}{{6.4}{108}{3.6.4 3D 图解未归一化}{subsection.3.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.4}{3.6.4 3D 图解未归一化}}{108}{subsection.3.6.4}}
\newlabel{ux5f52ux4e00ux5316ux6709ux54eaux4e9bux7c7bux578b}{{6.5}{108}{3.6.5 归一化有哪些类型？}{subsection.3.6.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.5}{3.6.5 归一化有哪些类型？}}{108}{subsection.3.6.5}}
\newlabel{ux5c40ux90e8ux54cdux5e94ux5f52ux4e00ux5316ux4f5cux7528}{{6.6}{109}{3.6.6 局部响应归一化作用}{subsection.3.6.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.6}{3.6.6 局部响应归一化作用}}{109}{subsection.3.6.6}}
\newlabel{ux7406ux89e3ux5c40ux90e8ux54cdux5e94ux5f52ux4e00ux5316}{{6.7}{109}{3.6.7 理解局部响应归一化}{subsection.3.6.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.7}{3.6.7 理解局部响应归一化}}{109}{subsection.3.6.7}}
\newlabel{ux4ec0ux4e48ux662fux6279ux5f52ux4e00ux5316batch-normalization}{{6.8}{110}{3.6.8 什么是批归一化（Batch Normalization）}{subsection.3.6.8}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.8}{3.6.8 什么是批归一化（Batch Normalization）}}{110}{subsection.3.6.8}}
\newlabel{ux6279ux5f52ux4e00ux5316bnux7b97ux6cd5ux7684ux4f18ux70b9}{{6.9}{110}{3.6.9 批归一化（BN）算法的优点}{subsection.3.6.9}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.9}{3.6.9 批归一化（BN）算法的优点}}{110}{subsection.3.6.9}}
\newlabel{ux6279ux5f52ux4e00ux5316bnux7b97ux6cd5ux6d41ux7a0b}{{6.10}{110}{3.6.10 批归一化（BN）算法流程}{subsection.3.6.10}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.10}{3.6.10 批归一化（BN）算法流程}}{110}{subsection.3.6.10}}
\gdef \LT@xxiii {\LT@entry 
    \par }
\newlabel{ux6279ux5f52ux4e00ux5316ux548cux7fa4ux7ec4ux5f52ux4e00ux5316ux6bd4ux8f83}{{6.11}{111}{3.6.11 批归一化和群组归一化比较}{subsection.3.6.11}{}}
\newlabel{weight-normalizationux548cbatch-normalizationux6bd4ux8f83}{{6.12}{111}{3.6.12 Weight Normalization和Batch Normalization比较}{subsection.3.6.12}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.12}{3.6.12 Weight Normalization和Batch Normalization比较}}{111}{subsection.3.6.12}}
\newlabel{batch-normalizationux5728ux4ec0ux4e48ux65f6ux5019ux7528ux6bd4ux8f83ux5408ux9002}{{6.13}{112}{3.6.13 Batch Normalization在什么时候用比较合适？}{subsection.3.6.13}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.13}{3.6.13 Batch Normalization在什么时候用比较合适？}}{112}{subsection.3.6.13}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{7}{3.7 预训练与微调(fine tuning)}}{112}{section.3.7}}
\newlabel{ux9884ux8badux7ec3ux4e0eux5faeux8c03fine-tuning}{{7}{112}{3.7 预训练与微调(fine tuning)}{section.3.7}{}}
\newlabel{ux4e3aux4ec0ux4e48ux65e0ux76d1ux7763ux9884ux8badux7ec3ux53efux4ee5ux5e2eux52a9ux6df1ux5ea6ux5b66ux4e60}{{7.1}{112}{3.7.1 为什么无监督预训练可以帮助深度学习？}{subsection.3.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.1}{3.7.1 为什么无监督预训练可以帮助深度学习？}}{112}{subsection.3.7.1}}
\newlabel{ux4ec0ux4e48ux662fux6a21ux578bux5faeux8c03fine-tuning}{{7.2}{112}{3.7.2 什么是模型微调fine tuning}{subsection.3.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.2}{3.7.2 什么是模型微调fine tuning}}{112}{subsection.3.7.2}}
\newlabel{ux5faeux8c03ux65f6ux5019ux7f51ux7edcux53c2ux6570ux662fux5426ux66f4ux65b0}{{7.3}{112}{3.7.3 微调时候网络参数是否更新？}{subsection.3.7.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.3}{3.7.3 微调时候网络参数是否更新？}}{112}{subsection.3.7.3}}
\newlabel{fine-tuning-ux6a21ux578bux7684ux4e09ux79cdux72b6ux6001}{{7.4}{113}{3.7.4 fine-tuning 模型的三种状态}{subsection.3.7.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{7.4}{3.7.4 fine-tuning 模型的三种状态}}{113}{subsection.3.7.4}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{8}{3.8 权重偏差初始化}}{113}{section.3.8}}
\newlabel{ux6743ux91cdux504fux5deeux521dux59cbux5316}{{8}{113}{3.8 权重偏差初始化}{section.3.8}{}}
\newlabel{ux5168ux90fdux521dux59cbux5316ux4e3a-0}{{8.1}{113}{3.8.1 全都初始化为 0}{subsection.3.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.1}{3.8.1 全都初始化为 0}}{113}{subsection.3.8.1}}
\newlabel{ux5168ux90fdux521dux59cbux5316ux4e3aux540cux6837ux7684ux503c}{{8.2}{113}{3.8.2 全都初始化为同样的值}{subsection.3.8.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.2}{3.8.2 全都初始化为同样的值}}{113}{subsection.3.8.2}}
\newlabel{ux521dux59cbux5316ux4e3aux5c0fux7684ux968fux673aux6570}{{8.3}{114}{3.8.3 初始化为小的随机数}{subsection.3.8.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.3}{3.8.3 初始化为小的随机数}}{114}{subsection.3.8.3}}
\gdef \LT@xxiv {\LT@entry 
    {2}{97.31868pt}\LT@entry 
    {2}{273.4842pt}}
\newlabel{ux7528-1n-ux6821ux51c6ux65b9ux5dee}{{8.4}{115}{\texorpdfstring {3.8.4 用 $ 1/\sqrt n $ 校准方差}{3.8.4 用 $ 1/n $ 校准方差}}{subsection.3.8.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.4}{3.8.4 用 $ 1/\sqrt  n $ 校准方差}}{115}{subsection.3.8.4}}
\newlabel{ux7a00ux758fux521dux59cbux5316sparse-initialazation}{{8.5}{115}{3.8.5 稀疏初始化(Sparse Initialazation)}{subsection.3.8.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.5}{3.8.5 稀疏初始化(Sparse Initialazation)}}{115}{subsection.3.8.5}}
\newlabel{ux521dux59cbux5316ux504fux5dee}{{8.6}{115}{3.8.6 初始化偏差}{subsection.3.8.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{8.6}{3.8.6 初始化偏差}}{115}{subsection.3.8.6}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{9}{3.9 学习率}}{115}{section.3.9}}
\newlabel{ux5b66ux4e60ux7387}{{9}{115}{3.9 学习率}{section.3.9}{}}
\newlabel{ux5b66ux4e60ux7387ux7684ux4f5cux7528}{{9.1}{115}{3.9.1 学习率的作用}{subsection.3.9.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.1}{3.9.1 学习率的作用}}{115}{subsection.3.9.1}}
\newlabel{ux5b66ux4e60ux7387ux8870ux51cfux5e38ux7528ux53c2ux6570ux6709ux54eaux4e9b}{{9.2}{115}{学习率衰减常用参数有哪些}{subsection.3.9.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.2}{学习率衰减常用参数有哪些}}{116}{table.3.3}}
\newlabel{ux5206ux6bb5ux5e38ux6570ux8870ux51cf}{{9.3}{116}{分段常数衰减}{subsection.3.9.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.3}{分段常数衰减}}{116}{subsection.3.9.3}}
\newlabel{ux6307ux6570ux8870ux51cf}{{9.4}{116}{指数衰减}{subsection.3.9.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.4}{ 指数衰减}}{116}{subsection.3.9.4}}
\newlabel{ux81eaux7136ux6307ux6570ux8870ux51cf}{{9.5}{116}{自然指数衰减}{subsection.3.9.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.5}{自然指数衰减}}{116}{subsection.3.9.5}}
\newlabel{ux591aux9879ux5f0fux8870ux51cf}{{9.6}{116}{多项式衰减}{subsection.3.9.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.6}{ 多项式衰减}}{116}{subsection.3.9.6}}
\newlabel{ux4f59ux5f26ux8870ux51cf}{{9.7}{117}{余弦衰减}{subsection.3.9.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{9.7}{ 余弦衰减}}{117}{subsection.3.9.7}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{10}{ Dropout系列问题}}{117}{section.3.10}}
\newlabel{dropout-ux7cfbux5217ux95eeux9898}{{10}{117}{Dropout系列问题}{section.3.10}{}}
\newlabel{ux4e3aux4ec0ux4e48ux8981ux6b63ux5219ux5316}{{10.1}{117}{为什么要正则化？}{subsection.3.10.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.1}{为什么要正则化？}}{117}{subsection.3.10.1}}
\newlabel{ux4e3aux4ec0ux4e48ux6b63ux5219ux5316ux6709ux5229ux4e8eux9884ux9632ux8fc7ux62dfux5408}{{10.2}{118}{为什么正则化有利于预防过拟合？}{subsection.3.10.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.2}{为什么正则化有利于预防过拟合？}}{118}{subsection.3.10.2}}
\newlabel{ux7406ux89e3dropoutux6b63ux5219ux5316}{{10.3}{118}{理解dropout正则化}{subsection.3.10.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.3}{理解dropout正则化}}{118}{subsection.3.10.3}}
\newlabel{dropoutux7387ux7684ux9009ux62e9}{{10.4}{118}{dropout率的选择}{subsection.3.10.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.4}{dropout率的选择}}{118}{subsection.3.10.4}}
\newlabel{dropoutux6709ux4ec0ux4e48ux7f3aux70b9}{{10.5}{118}{dropout有什么缺点？}{subsection.3.10.5}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{10.5}{dropout有什么缺点？}}{118}{subsection.3.10.5}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{11}{深度学习中常用的数据增强方法？}}{119}{section.3.11}}
\newlabel{ux6df1ux5ea6ux5b66ux4e60ux4e2dux5e38ux7528ux7684ux6570ux636eux589eux5f3aux65b9ux6cd5}{{11}{119}{深度学习中常用的数据增强方法？}{section.3.11}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{12}{如何理解 Internal CovariateShift？}}{119}{section.3.12}}
\newlabel{ux5982ux4f55ux7406ux89e3-internal-covariate-shift}{{12}{119}{如何理解 Internal CovariateShift？}{section.3.12}{}}
\gdef \LT@xxv {\LT@entry 
    {1}{61.59845pt}\LT@entry 
    {1}{78.8023pt}\LT@entry 
    {1}{91.70192pt}\LT@entry 
    {1}{78.8023pt}\LT@entry 
    {1}{113.20346pt}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.2}{4.1.2 模型结构}}{123}{figure.4.1}}
\gdef \LT@xxvi {\LT@entry 
    {1}{57.30077pt}\LT@entry 
    {1}{87.39767pt}\LT@entry 
    {1}{95.9996pt}\LT@entry 
    {1}{87.39767pt}\LT@entry 
    {1}{91.70192pt}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2}{4.2.2 模型结构}}{124}{figure.4.3}}
\newlabel{ux6a21ux578bux7279ux6027-2}{{3.3}{125}{4.3.3 模型特性}{subsection.4.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.3}{4.3.3 模型特性}}{125}{subsection.4.3.3}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{4}{4.4 Network in Network}}{125}{section.4.4}}
\newlabel{network-in-network}{{4}{125}{4.4 Network in Network}{section.4.4}{}}
\newlabel{ux6a21ux578bux4ecbux7ecd-3}{{4.1}{125}{4.4.1 模型介绍}{subsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.1}{4.4.1 模型介绍}}{125}{subsection.4.4.1}}
\newlabel{ux6a21ux578bux7ed3ux6784-3}{{4.2}{126}{4.4.2 模型结构}{subsection.4.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.2}{4.4.2 模型结构}}{126}{subsection.4.4.2}}
\gdef \LT@xxvii {\LT@entry 
    {1}{57.30077pt}\LT@entry 
    {1}{61.59845pt}\LT@entry 
    {1}{57.30077pt}\LT@entry 
    {1}{65.9027pt}\LT@entry 
    {1}{61.59845pt}}
\newlabel{ux6a21ux578bux7279ux70b9}{{4.3}{127}{4.4.3 模型特点}{subsection.4.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.3}{4.4.3 模型特点}}{127}{subsection.4.4.3}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.2}{4.5.2 模型结构}}{128}{figure.4.8}}
\gdef \LT@xxviii {\LT@entry 
    {1}{78.8023pt}\LT@entry 
    {1}{74.49806pt}\LT@entry 
    {1}{83.09999pt}\LT@entry 
    {1}{78.8023pt}\LT@entry 
    {1}{104.60153pt}}
\newlabel{ux6a21ux578bux7279ux6027-3}{{5.3}{129}{4.5.3 模型特性}{subsection.4.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.3}{4.5.3 模型特性}}{129}{subsection.4.5.3}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{6}{4.6 GoogLeNet}}{129}{section.4.6}}
\newlabel{googlenet}{{6}{129}{4.6 GoogLeNet}{section.4.6}{}}
\newlabel{ux6a21ux578bux4ecbux7ecd-5}{{6.1}{129}{4.6.1 模型介绍}{subsection.4.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.1}{4.6.1 模型介绍}}{129}{subsection.4.6.1}}
\newlabel{ux6a21ux578bux7ed3ux6784-5}{{6.2}{130}{4.6.2 模型结构}{subsection.4.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.2}{4.6.2 模型结构}}{131}{subsection.4.6.2}}
\gdef \LT@xxix {\LT@entry 
    {1}{78.8023pt}\LT@entry 
    {1}{74.49806pt}\LT@entry 
    {1}{83.09999pt}\LT@entry 
    {1}{78.8023pt}\LT@entry 
    {1}{104.60153pt}}
\newlabel{ux6a21ux578bux7279ux6027-4}{{6.3}{132}{4.6.3 模型特性}{subsection.4.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{6.3}{4.6.3 模型特性}}{132}{subsection.4.6.3}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{7}{Restnet}}{132}{section.4.7}}
\newlabel{restnet}{{7}{132}{Restnet}{section.4.7}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{8}{Densenet}}{132}{section.4.8}}
\newlabel{densenet}{{8}{132}{Densenet}{section.4.8}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{9}{4.7 为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？}}{132}{section.4.9}}
\newlabel{ux4e3aux4ec0ux4e48ux73b0ux5728ux7684cnnux6a21ux578bux90fdux662fux5728googlenetvggnetux6216ux8005alexnetux4e0aux8c03ux6574ux7684}{{9}{132}{4.7 为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？}{section.4.9}{}}
\gdef \LT@xxx {\LT@entry 
    {1}{79.08556pt}\LT@entry 
    {2}{91.98056pt}\LT@entry 
    {2}{395.0242pt}}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{5}{卷积神经网络（CNN）}}{137}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ux7b2cux4e94ux7ae0-ux5377ux79efux795eux7ecfux7f51ux7edccnn}{{5}{137}{卷积神经网络（CNN）}{chapter.5}{}}
\newlabel{ux5377ux79efux795eux7ecfux7f51ux7edcux7684ux7ec4ux6210ux5c42}{{0.1}{137}{5.1 卷积神经网络的组成层}{subsection.5.0.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.1}{5.1 卷积神经网络的组成层}}{137}{subsection.5.0.1}}
\newlabel{ux8f93ux5165ux5c42}{{0.1.1}{137}{5.1.1 输入层}{subsubsection.5.0.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{0.1.1}{5.1.1 输入层}}{137}{subsubsection.5.0.1.1}}
\newlabel{ux5377ux79efux5c42}{{0.1.2}{138}{5.1.2 卷积层}{subsubsection.5.0.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{0.1.2}{5.1.2 卷积层}}{138}{subsubsection.5.0.1.2}}
\newlabel{ux6fc0ux6d3bux5c42}{{0.1.3}{139}{5.1.3 激活层}{subsubsection.5.0.1.3}{}}
\gdef \LT@xxxi {\LT@entry 
    {1}{52.15747pt}\LT@entry 
    {1}{52.15747pt}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{0.1.3}{5.1.3 激活层}}{140}{subsubsection.5.0.1.3}}
\newlabel{ux6c60ux5316ux5c42}{{0.1.4}{140}{5.1.4 池化层}{subsubsection.5.0.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{0.1.4}{5.1.4 池化层}}{140}{subsubsection.5.0.1.4}}
\newlabel{ux5168ux8fdeux63a5ux5c42}{{0.1.5}{140}{5.1.5 全连接层}{subsubsection.5.0.1.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{0.1.5}{5.1.5 全连接层}}{140}{subsubsection.5.0.1.5}}
\newlabel{ux5377ux79efux5728ux56feux50cfux4e2dux6709ux4ec0ux4e48ux76f4ux89c2ux4f5cux7528}{{0.2}{140}{5.2 卷积在图像中有什么直观作用}{subsection.5.0.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.2}{5.2 卷积在图像中有什么直观作用}}{140}{subsection.5.0.2}}
\gdef \LT@xxxii {\LT@entry 
    {1}{83.09999pt}\LT@entry 
    {1}{186.30347pt}\LT@entry 
    {1}{156.2pt}}
\gdef \LT@xxxiii {\LT@entry 
    {1}{78.8023pt}\LT@entry 
    {1}{173.40387pt}\LT@entry 
    {1}{173.40387pt}}
\newlabel{ux5377ux79efux5c42ux6709ux54eaux4e9bux57faux672cux53c2ux6570}{{0.3}{143}{5.3 卷积层有哪些基本参数？}{subsection.5.0.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.3}{5.3 卷积层有哪些基本参数？}}{143}{subsection.5.0.3}}
\newlabel{ux5377ux79efux6838ux6709ux4ec0ux4e48ux7c7bux578b}{{0.4}{144}{5.4 卷积核有什么类型？}{subsection.5.0.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.4}{5.4 卷积核有什么类型？}}{144}{subsection.5.0.4}}
\gdef \LT@xxxiv {\LT@entry 
    {1}{108.89922pt}\LT@entry 
    {1}{104.60153pt}\LT@entry 
    {1}{207.80502pt}}
\gdef \LT@xxxv {\LT@entry 
    {1}{121.79883pt}\LT@entry 
    {2}{134.69844pt}\LT@entry 
    {1}{164.80194pt}}
\newlabel{ux6709ux54eaux4e9bux6c60ux5316ux65b9ux6cd5}{{0.6}{148}{5.7 有哪些池化方法？}{subsection.5.0.6}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.6}{5.7 有哪些池化方法？}}{148}{subsection.5.0.6}}
\gdef \LT@xxxvi {\LT@entry 
    {2}{41.6181pt}\LT@entry 
    {2}{210.24799pt}\LT@entry 
    {2}{178.62988pt}}
\newlabel{ux5377ux79efux5c42ux548cux6c60ux5316ux5c42ux6709ux4ec0ux4e48ux533aux522b}{{0.8}{151}{5.9 卷积层和池化层有什么区别？}{subsection.5.0.8}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.8}{5.9 卷积层和池化层有什么区别？}}{151}{subsection.5.0.8}}
\newlabel{ux5377ux79efux6838ux662fux5426ux4e00ux5b9aux8d8aux5927ux8d8aux597d}{{0.9}{151}{5.10 卷积核是否一定越大越好？}{subsection.5.0.9}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.9}{5.10 卷积核是否一定越大越好？}}{151}{subsection.5.0.9}}
\newlabel{ux6bcfux5c42ux5377ux79efux662fux5426ux53eaux80fdux7528ux4e00ux79cdux5c3aux5bf8ux7684ux5377ux79efux6838}{{0.10}{151}{5.11 每层卷积是否只能用一种尺寸的卷积核？}{subsection.5.0.10}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.10}{5.11 每层卷积是否只能用一种尺寸的卷积核？}}{151}{subsection.5.0.10}}
\newlabel{ux68cbux76d8ux6548ux5e94}{{0.14.3}{152}{5.15.3 棋盘效应}{subsubsection.5.0.14.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{0.14.3}{5.15.3 棋盘效应}}{152}{subsubsection.5.0.14.3}}
\newlabel{ux5377ux79efux795eux7ecfux7f51ux7edcux7684ux53c2ux6570ux8bbeux7f6e}{{0.15}{152}{5.16 卷积神经网络的参数设置}{subsection.5.0.15}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.15}{5.16 卷积神经网络的参数设置}}{152}{subsection.5.0.15}}
\gdef \LT@xxxvii {\LT@entry 
    {1}{48.69884pt}\LT@entry 
    {1}{53.00308pt}\LT@entry 
    {1}{44.40117pt}}
\newlabel{ux63d0ux9ad8ux5377ux79efux795eux7ecfux7f51ux7edcux7684ux6cdbux5316ux80fdux529b}{{0.16}{156}{5.17 提高卷积神经网络的泛化能力}{subsection.5.0.16}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.16}{5.17 提高卷积神经网络的泛化能力}}{156}{subsection.5.0.16}}
\gdef \LT@xxxviii {\LT@entry 
    {1}{44.40115pt}\LT@entry 
    {1}{40.10349pt}}
\newlabel{ux5377ux79efux795eux7ecfux7f51ux7edcux5728ux4e0dux540cux9886ux57dfux7684ux5e94ux7528}{{0.17}{164}{5.18 卷积神经网络在不同领域的应用}{subsection.5.0.17}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{0.17}{5.18 卷积神经网络在不同领域的应用}}{164}{subsection.5.0.17}}
\newlabel{ux8054ux7cfb}{{0.17.1}{167}{5.18.1 